正则化：对学习算法的修改——旨在减少泛化误差而不是训练误差。  

1. 向机器学习模型添加限制参数值的额外约束。  
2. 向目标函数增加额外项来对参数值进行软约束。  
3. 结合多个假说来解释训练数据。  

> **[success]**  
> 训练集上效果不好时，使用第8章的方法。  
> 训练集上效果好而测试集上效果不好时，使用第7章的方法。  
> **正则化输入**  
> 这一段内容是Ag的视频课上讲的，不知道放哪，就放这里了。  
> 输入数据的正则化 = 零均值化 + 方差归一化  
> ![](/assets/images/Chapter7/12.png)  
> 优点：可以加速训练  
> 注意：训练集做计算出来的用于归一化的均值和方差要记下来，测试集不能使用自己的均值和方差，而应该使用训练集的均值和方差。  
> 原理：归一化之后，所有特征都在同一尺度下 ==> J更圆 ==> 更容易优化  









