# 带约束的最小化问题

换一个角度来看待参数范数惩罚。  
代价函数还是原来的代价函数$$J(\theta;X,y)$$  
通过给参数增加一个显示的约束条件$$\Omega(\theta)<k$$来限制参数的大小。  
这时最小化代价函数的问题就变成了带约束的最小化代价函数的问题了。  
$$
\min J(\theta;X,y) \\
s.t. \Omega(\theta)<k
$$

使用[KKT](https://windmising.gitbook.io/mathematics-basic-for-ml/shu-zhi-ji-suan/constrainedoptimization)算法求解带约束的最小化问题，解为：  
$$
\theta* = {\arg \min}_{\theta} \max_{\alpha,\alpha>0}{\cal L}(\theta, \alpha)
$$

求解这些带约束的最小化问题不是这一节的重点。  
这一节的重点是比较“显式约束”和“参数范数惩罚”这两个思考角度。  

# “显式约束” VS “参数范数惩罚”

## 目的

使用“显式约束”和“参数范数惩罚”的目的都是一样的：限制参数的大小。  

## 效果

实现效果不略有不同：  
“参数范数惩罚”鼓励参数向原点靠近。  
而“显式约束”只关心参数是不是在约束区域内，只有在参数试图离开约束区域时约束才会起作用。  

## 好处

显式约束的好处：  
1. 如果知道什么样的k是合适的，使用“显式约束”可以省去不必要的搜索。  
2. “参数范数惩罚”容易使算法陷入局部最小，而“显式约束”不会。  
3. [?]“显式约束”对优化过程增加了稳定性。建议结合使用约束和高学习速率，这样能更快地探索参数空间，并保持一定的稳定性。  
4. 通过“显式约束”，可以分别限制每一层的参数。  