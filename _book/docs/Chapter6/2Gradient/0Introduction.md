# 神经网络中的梯度下降法  VS 其它模型中的梯度下降法

1. 没有太大不同  
2. 只能使用迭代方法，不能直接使用线性方程求解，  
3. 神经网络中的代价函数通常是非凸的，因此不一定能找到最小的值。  
4. 对参数的初始值敏感，通常w使用小的随机值，b使用小的正值。

在非凸函数中，梯度下降法的结果与初始化值有关，关于参数的初始化见第8章。  
梯度下降法及其改进见4.5。  
随机梯度下降法见5.9。  
使用反向传播算法快速计算神经网络的梯度，见6.5。  