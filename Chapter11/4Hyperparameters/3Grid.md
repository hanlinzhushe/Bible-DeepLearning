当有三个或更少的超参数时，常见的超参数搜索方法是网格搜索。
对于每个超参数，使用者选择一个较小的有限值集去探索。
然后，这些超参数笛卡尔乘积得到一组组超参数，网格搜索使用每组超参数训练模型。
挑选验证集误差最小的超参数作为最好的超参数。
如\fig?所示超参数值的网格。
<!-- % -- 420 end -->


\begin{figure}[!htb]
\ifOpenSource
\centerline{\includegraphics{figure.pdf}}
\else
\begin{tabular}{cc}
\includegraphics[width=0.35\textwidth]{Chapter11/figures/grid} &
\includegraphics[width=0.35\textwidth]{Chapter11/figures/random}
\end{tabular}
\fi
\caption{网格搜索和随机搜索的比较。
为了方便地说明，我们只展示两个超参数的例子，但是我们关注的问题中超参数个数通常会更多。
\emph{(左)}为了实现网格搜索，我们为每个超参数提供了一个值的集合。
搜索算法对每一种在这些集合的交叉积中的超参数组合进行训练。
\emph{(右)}为了实现随机搜索，我们给联合超参数赋予了一个概率分布。
通常超参数之间是相互独立的。
常见的这种分布的选择是均匀分布或者是对数均匀（从对数均匀分布中抽样，就是对从均匀分布中抽取的样本进行指数运算）的。
然后这些搜索算法从联合的超参数空间中采样，然后运行每一个样本。
网格搜索和随机搜索都运行了验证集上的误差并返回了最优的解。
这个图说明了通常只有一个超参数对结果有着重要的影响。
在这个例子中，只有水平轴上的超参数对结果有重要的作用。
网格搜索将大量的计算浪费在了指数量级的对结果无影响的超参数中，相比之下随机搜索几乎每次测试都测试了对结果有影响的每个超参数的独一无二的值。
此图经~{Bergstra+Bengio-LW2011}允许转载。}
\end{figure}


应该如何选择搜索集合的范围呢？
在超参数是数值（有序）的情况下，每个列表的最小和最大的元素可以基于先前相似实验的经验保守地挑选出来，以确保最优解非常可能在所选范围内。
通常，网格搜索大约会在对数尺度下挑选合适的值，例如，一个学习率的取值集合是$\{0.1,0.01,10^{-3},10^{-4},10^{-5}\}$，或者隐藏单元数目的取值集合$\{50,100,200,500,1000,2000\}$。
<!-- % 421 head -->


通常重复进行网格搜索时，效果会最好。
例如，假设我们在集合$\{-1,0,1\}$上网格搜索超参数 $\alpha$。
如果找到的最佳值是$1$，那么说明我们低估了最优值$\alpha$所在的范围，应该改变搜索格点，例如在集合$\{1,2,3\}$中搜索。
如果最佳值是$0$，那么我们不妨通过细化搜索范围以改进估计，在集合$\{-0.1,0,0.1\}$上进行网格搜索。
<!-- % -- 422 head -->


网格搜索带来的一个明显问题是，计算代价会随着超参数数量呈指数级增长。
如果有$m$个超参数，每个最多取$n$个值，那么训练和估计所需的试验数将是$O(n^m)$。
我们可以并行地进行实验，并且并行要求十分宽松（进行不同搜索的机器之间几乎没有必要进行通信）。
令人遗憾的是，由于网格搜索指数级增长的计算代价，即使是并行，我们也无法提供令人满意的搜索规模。

