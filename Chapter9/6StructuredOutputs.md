卷积神经网络可以用于输出高维的结构化对象，而不仅仅是预测分类任务的类标签或回归任务的实数值。
通常这个对象只是一个张量，由标准卷积层产生。
例如，模型可以产生张量$S$，其中$S_{i,j,k}$是网络的输入像素$(j, k)$属于类$i$的概率。
这允许模型标记图像中的每个像素，并绘制沿着单个对象轮廓的精确掩模。  
> **[success]**  
> CNN可以对图像进行逐元素分类，并八绘制单个对象的轮廓。  

# 结构化输出要解决的问题

经常出现的一个问题是输出平面可能比输入平面要小，如\fig?所示。
用于对图像中单个对象分类的常用结构中，网络空间维数的最大减少来源于使用大步幅的池化层。
为了产生与输入大小相似的输出映射，我们可以完全避免使用池化{cite?}。
另一种策略是单纯地产生一张低分辨率的标签网格{cite?}。
最后，原则上可以使用具有单位步幅的池化操作。  
> **[success]**  
> 结构化输出要解决的问题：输出比输入小  
> 原因：池化  
> 解决方法：（1）避免池化[?](2)产生低分辨率的图像  

# 怎样产生结构化输出  

> **[success]**  
（1）先产生图像标签的原始猜测  
（2）使用相邻像素之间的交互来修正该原始猜测  
（3）进一步处理这些预测  

对图像逐个像素标记的一种策略是先产生图像标签的原始猜测，然后使用相邻像素之间的交互来修正该原始猜测。  
重复这个修正步骤数次对应于在每一步使用相同的卷积，该卷积在深层网络的最后几层之间共享权重{cite?}。
这使得在层之间共享参数的连续的卷积层所执行的一系列运算，形成了一种特殊的循环神经网络~{cite?}。
\fig?给出了这样一个循环卷积网络的结构。
<!-- % fig 9.17 -->
\begin{figure}[!htb]
\ifOpenSource
\centerline{\includegraphics{figure.pdf}}
\else
\centerline{\includegraphics{Chapter9/figures/iterative}}
\fi
\captionsetup{singlelinecheck=off}
\caption[.]{用于像素标记的循环卷积网络的示例。
输入是图像张量$X$，它的轴对应图像的行、列和通道（红，绿，蓝）。
目标是输出标签张量$\hat{Y}$，它遵循每个像素的标签的概率分布。
该张量的轴对应图像的行、列和不同类别。
循环网络通过使用$\hat{Y}$的先前估计作为创建新估计的输入，来迭代地改善其估计，而不是单次输出$\hat{Y}$，。
每个更新的估计使用相同的参数，并且估计可以如我们所愿地被改善任意多次。
每一步使用的卷积核张量$U$，是用来计算给定输入图像的隐藏表示的。
核张量$V$用于产生给定隐藏值时标签的估计。
除了第一步之外，核$W$都对$\hat{Y}$进行卷积来提供隐藏层的输入。
在第一步中，此项由零代替。
因为每一步使用相同的参数，所以这是一个循环网络的例子，如\chap?所述。}
\end{figure}

<!-- % -- 347 -- -->
 
一旦对每个像素都进行了预测，我们就可以使用各种方法来进一步处理这些预测，以便获得图像在区域上的分割{cite?}。
一般的想法是假设大片相连的像素倾向于对应着相同的标签。
图模型可以描述相邻像素间的概率关系。
或者，卷积网络可以被训练来最大化地近似图模型的训练目标{cite?}。