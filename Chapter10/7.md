学习循环网络长期依赖的数学挑战在第8.2.5节中引入。
根本问题是，经过许多阶段传播后的梯度倾向于消失（大部分情况）或爆炸（很少，但对优化过程影响很大）。
即使我们假设循环网络是参数稳定的（可存储记忆，且梯度不爆炸），但长期依赖的困难来自比短期相互作用指数小的权重（涉及许多Jacobian相乘）。  
> **[warning]**  
> 可存储记忆可解决梯度消失问题。  
> 既然假设梯度消失已解决，梯度爆炸不存在，还讨论啥？  
> “比短期相互作用指数小的权重”是什么？

许多资料提供了更深层次的讨论{cite?}。
在这一节中，我们会更详细地描述该问题。
其余几节介绍克服这个问题的方法。

循环网络涉及相同函数的多次组合，每个时间步一次。
这些组合可以导致极端非线性行为，如\fig?所示。  

{% reveal %}
\begin{figure}[!htb]
\ifOpenSource
\centerline{\includegraphics{figure.pdf}}
\else
\centerline{\includegraphics{Chapter10/figures/composition_color}}
\fi
\caption{重复组合函数。
当组合许多非线性函数（如这里所示的线性tanh层）时，结果是高度非线性的，通常大多数值与微小的导数相关联，也有一些具有大导数的值，以及在增加和减小之间的多次交替。% ??
此处，我们绘制从100维隐藏状态降到单个维度的线性投影，绘制于$y$轴上。
$x$轴是100维空间中沿着随机方向的初始状态的坐标。
因此，我们可以将该图视为高维函数的线性截面。
曲线显示每个时间步之后的函数，或者等价地，转换函数被组合一定次数之后。
}
\end{figure}
{% endreveal %}

特别地，循环神经网络所使用的函数组合有点像矩阵乘法。
我们可以把如下的循环联系  
$$
\begin{aligned}
 h^{(t)} = W^\top h^{(t-1)}
\end{aligned}
$$

看做是一个非常简单的、缺少非线性激活函数和输入$x$的循环神经网络。
如\sec?描述，这种循环关系本质上描述了幂法。
它可以被简化为  
$$
\begin{aligned}
 h^{(t)} = (W^t)^\top h^{(0)},
\end{aligned}
$$

而当$W$符合下列形式的特征分解  
$$
\begin{aligned}
 W = Q \Lambda Q^\top,
\end{aligned}
$$

其中$Q$正交，循环性可进一步简化为  
$$
\begin{aligned}
 h^{(t)} = Q^\top Lambda^t Q h^{(0)}.
\end{aligned}
$$

特征值提升到$t$次后，导致幅值不到一的特征值衰减到零，而幅值大于一的就会激增。
**任何不与最大特征向量对齐的$h^{(0)}$的部分将最终被丢弃**。


这个问题是针对循环网络的。
在标量情况下，想象多次乘一个权重$w$。
该乘积$w^t$消失还是爆炸取决于$w$的幅值。
然而，如果每个时刻使用不同权重$w^{(t)}$的非循环网络，情况就不同了。
如果初始状态给定为$1$，那么时刻$t$的状态可以由$\prod_t w^{(t)}$给出。
假设$w^{(t)}$的值是随机生成的，各自独立，且有$0$均值$v$方差。
乘积的方差就为$\Bbb O(v^n)$。
为了获得某个期望的方差$v^*$，我们可以选择让单个权重的方差为$v=\sqrt[n]{v^*}$。
因此，非常深的前馈网络通过精心设计的比例可以避免梯度消失和爆炸问题，如{Sussillo14}所主张的。
> **[success]**  
> 非循环网络每个时刻的$w^{(t)}$不同，通过合理设计$w^{(t)}$，可以避免梯度消失和爆炸问题。  

RNN梯度消失和爆炸问题是由不同研究人员独立发现{cite?}。
有人可能会希望通过简单地停留在梯度不消失或爆炸的参数空间来避免这个问题。
不幸的是，为了储存记忆并对小扰动具有鲁棒性，RNN必须进入参数空间中的梯度消失区域{cite?}。
具体来说，每当模型能够表示长期依赖时，长期相互作用的梯度幅值就会变得指数级小（相比短期相互作用的梯度幅值）。
这并不意味着这是不可能学习的，由于长期依赖关系的信号很容易被短期相关性产生的最小波动隐藏，因而学习长期依赖可能需要很长的时间。
实践中，{Bengio1994ITNN}的实验表明，当我们增加了需要捕获的依赖关系的跨度，基于梯度的优化变得越来越困难，SGD在长度仅为10或20的序列上成功训练传统RNN的概率迅速变为0。  
> **[warning]** 这一整段看不懂

将循环网络作为动力系统更深入探讨的资料见{Doya93,Bengio1994ITNN,Siegelmann+Sontag-1995}及
{Pascanu-et-al-ICML2013}的回顾。
本章的其余部分将讨论目前已经提出的降低学习长期依赖（在某些情况下，允许一个RNN学习横跨数百步的依赖）难度的不同方法，但学习长期依赖的问题仍是深度学习中的一个主要挑战。
