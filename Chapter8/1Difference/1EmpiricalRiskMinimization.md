结论：深度学习很少使用经验风险最小化  

# 风险与经验风险

**风险**：  

$$
J*(\theta) = E_{X,y\sim P_{data}}L(f(x;\theta),y)
$$
其中$$P_{data}$$指所有数据，因此$$J*(\theta)$$是泛化误差的期望，称为**风险**。  
$$
J(\theta) = E_{X,y\sim \hat P_{data}}L(f(x;\theta),y)
$$
其中$$\hat P_{data}$$指经验数据，也就是训练样本。因此$$J*(\theta)$$是经验误差的期望，称为**经验风险**。  

**只能最优化经验风险，不能最优化风险。**

*注意这里说的是最优化，不是最小化。*  

# 最小化经验风险的缺点

1. 经验风险最小化容易导致过拟合。  
2. 最优化算法是基于梯度的，但是很多有用的损失函数没有有用的导数。  
